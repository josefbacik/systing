//! DuckDB database generation from Parquet files.
//!
//! This module provides functionality for creating DuckDB databases from
//! Parquet trace files generated by systing.

use anyhow::{Context, Result};
use duckdb::Connection;
use std::path::Path;

use crate::parquet_paths::ParquetPaths;

/// Create DuckDB schema with all tables.
///
/// Creates tables for:
/// - Process and thread metadata
/// - Scheduler events (sched_slice, thread_state, IRQ, softirq)
/// - Events (slice, track, instant, args)
/// - Performance counters
/// - Stack traces (both legacy and query-friendly formats)
/// - Network events
/// - Clock snapshots
pub fn create_schema(conn: &Connection) -> Result<()> {
    conn.execute_batch(
        "
        CREATE TABLE IF NOT EXISTS _traces (
            trace_id VARCHAR PRIMARY KEY,
            source_path VARCHAR,
            import_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        );

        CREATE TABLE IF NOT EXISTS process (
            trace_id VARCHAR,
            upid BIGINT,
            pid INTEGER,
            name VARCHAR,
            parent_upid BIGINT,
            cmdline VARCHAR[]
        );

        CREATE TABLE IF NOT EXISTS thread (
            trace_id VARCHAR,
            utid BIGINT,
            tid INTEGER,
            name VARCHAR,
            upid BIGINT
        );

        CREATE TABLE IF NOT EXISTS sched_slice (
            trace_id VARCHAR,
            ts BIGINT,
            dur BIGINT,
            cpu INTEGER,
            utid BIGINT,
            end_state INTEGER,
            priority INTEGER
        );

        CREATE TABLE IF NOT EXISTS thread_state (
            trace_id VARCHAR,
            ts BIGINT,
            dur BIGINT,
            utid BIGINT,
            state VARCHAR,
            cpu INTEGER
        );

        CREATE TABLE IF NOT EXISTS irq_slice (
            trace_id VARCHAR,
            ts BIGINT,
            dur BIGINT,
            cpu INTEGER,
            irq INTEGER,
            name VARCHAR,
            ret INTEGER
        );

        CREATE TABLE IF NOT EXISTS softirq_slice (
            trace_id VARCHAR,
            ts BIGINT,
            dur BIGINT,
            cpu INTEGER,
            vec INTEGER
        );

        CREATE TABLE IF NOT EXISTS wakeup_new (
            trace_id VARCHAR,
            ts BIGINT,
            cpu INTEGER,
            utid BIGINT,
            target_cpu INTEGER
        );

        CREATE TABLE IF NOT EXISTS process_exit (
            trace_id VARCHAR,
            ts BIGINT,
            cpu INTEGER,
            utid BIGINT
        );

        CREATE TABLE IF NOT EXISTS counter_track (
            trace_id VARCHAR,
            id BIGINT,
            name VARCHAR,
            unit VARCHAR
        );

        CREATE TABLE IF NOT EXISTS counter (
            trace_id VARCHAR,
            ts BIGINT,
            track_id BIGINT,
            value DOUBLE
        );

        CREATE TABLE IF NOT EXISTS slice (
            trace_id VARCHAR,
            id BIGINT,
            ts BIGINT,
            dur BIGINT,
            track_id BIGINT,
            utid BIGINT,
            name VARCHAR,
            category VARCHAR,
            depth INTEGER
        );

        CREATE TABLE IF NOT EXISTS track (
            trace_id VARCHAR,
            id BIGINT,
            name VARCHAR,
            parent_id BIGINT
        );

        CREATE TABLE IF NOT EXISTS args (
            trace_id VARCHAR,
            slice_id BIGINT,
            key VARCHAR,
            int_value BIGINT,
            string_value VARCHAR,
            real_value DOUBLE
        );

        CREATE TABLE IF NOT EXISTS instant (
            trace_id VARCHAR,
            id BIGINT,
            ts BIGINT,
            track_id BIGINT,
            utid BIGINT,
            name VARCHAR,
            category VARCHAR
        );

        CREATE TABLE IF NOT EXISTS instant_args (
            trace_id VARCHAR,
            instant_id BIGINT,
            key VARCHAR,
            int_value BIGINT,
            string_value VARCHAR,
            real_value DOUBLE
        );

        -- Legacy stack trace tables (for Perfetto .pb file conversion)
        CREATE TABLE IF NOT EXISTS stack_profile_symbol (
            trace_id VARCHAR,
            id BIGINT,
            name VARCHAR
        );

        CREATE TABLE IF NOT EXISTS stack_profile_mapping (
            trace_id VARCHAR,
            id BIGINT,
            build_id VARCHAR,
            name VARCHAR,
            exact_offset BIGINT,
            start_offset BIGINT
        );

        CREATE TABLE IF NOT EXISTS stack_profile_frame (
            trace_id VARCHAR,
            id BIGINT,
            name VARCHAR,
            mapping_id BIGINT,
            rel_pc BIGINT,
            symbol_id BIGINT
        );

        CREATE TABLE IF NOT EXISTS stack_profile_callsite (
            trace_id VARCHAR,
            id BIGINT,
            parent_id BIGINT,
            frame_id BIGINT,
            depth INTEGER
        );

        CREATE TABLE IF NOT EXISTS perf_sample (
            trace_id VARCHAR,
            ts BIGINT,
            utid BIGINT,
            callsite_id BIGINT,
            cpu INTEGER
        );

        -- Query-friendly stack tables (new schema)
        CREATE TABLE IF NOT EXISTS stack (
            trace_id VARCHAR,
            id BIGINT,
            frame_names VARCHAR[],
            depth INTEGER,
            leaf_name VARCHAR
        );

        CREATE TABLE IF NOT EXISTS stack_sample (
            trace_id VARCHAR,
            ts BIGINT,
            utid BIGINT,
            cpu INTEGER,
            stack_id BIGINT,
            stack_event_type TINYINT
        );

        -- Network interface metadata
        CREATE TABLE IF NOT EXISTS network_interface (
            trace_id VARCHAR,
            namespace VARCHAR,
            interface_name VARCHAR,
            ip_address VARCHAR,
            address_type VARCHAR
        );

        -- Socket connection metadata (extracted from socket track names)
        CREATE TABLE IF NOT EXISTS socket_connection (
            trace_id VARCHAR,
            socket_id BIGINT,
            track_id BIGINT,
            protocol VARCHAR,
            src_ip VARCHAR,
            src_port INTEGER,
            dest_ip VARCHAR,
            dest_port INTEGER,
            address_family VARCHAR
        );

        -- New network tables (Phase 1 of network recorder refactor)
        CREATE TABLE IF NOT EXISTS network_syscall (
            trace_id VARCHAR,
            id BIGINT,
            ts BIGINT,
            dur BIGINT,
            tid INTEGER,
            pid INTEGER,
            event_type VARCHAR,
            socket_id BIGINT,
            bytes BIGINT,
            seq BIGINT,
            sndbuf_used BIGINT,
            sndbuf_limit BIGINT,
            sndbuf_fill_pct SMALLINT,
            recv_seq_start BIGINT,
            recv_seq_end BIGINT,
            rcv_nxt BIGINT,
            bytes_available BIGINT
        );

        CREATE TABLE IF NOT EXISTS network_packet (
            trace_id VARCHAR,
            id BIGINT,
            ts BIGINT,
            socket_id BIGINT,
            event_type VARCHAR,
            seq BIGINT,
            length INTEGER,
            tcp_flags VARCHAR,
            -- Send buffer fields
            sndbuf_used BIGINT,
            sndbuf_limit BIGINT,
            sndbuf_fill_pct SMALLINT,
            -- Retransmit fields
            is_retransmit BOOLEAN,
            retransmit_count SMALLINT,
            rto_ms INTEGER,
            srtt_ms INTEGER,
            rttvar_us INTEGER,
            backoff SMALLINT,
            -- Zero window fields
            is_zero_window_probe BOOLEAN,
            is_zero_window_ack BOOLEAN,
            probe_count SMALLINT,
            -- Window fields
            snd_wnd INTEGER,
            rcv_wnd INTEGER,
            rcv_buf_used BIGINT,
            rcv_buf_limit BIGINT,
            window_clamp INTEGER,
            rcv_wscale SMALLINT,
            -- Timer fields
            icsk_pending SMALLINT,
            icsk_timeout BIGINT,
            -- Drop fields
            drop_reason INTEGER,
            drop_reason_str VARCHAR,
            drop_location BIGINT,
            -- Queue fields
            qlen INTEGER,
            qlen_limit INTEGER,
            -- TSQ fields
            sk_wmem_alloc BIGINT,
            tsq_limit BIGINT,
            -- TX queue fields
            txq_state INTEGER,
            qdisc_state INTEGER,
            qdisc_backlog BIGINT,
            -- SKB correlation
            skb_addr BIGINT,
            qdisc_latency_us INTEGER
        );

        CREATE TABLE IF NOT EXISTS network_socket (
            trace_id VARCHAR,
            socket_id BIGINT,
            protocol VARCHAR,
            address_family VARCHAR,
            src_ip VARCHAR,
            src_port INTEGER,
            dest_ip VARCHAR,
            dest_port INTEGER,
            first_seen_ts BIGINT,
            last_seen_ts BIGINT
        );

        CREATE TABLE IF NOT EXISTS network_poll (
            trace_id VARCHAR,
            id BIGINT,
            ts BIGINT,
            tid INTEGER,
            pid INTEGER,
            socket_id BIGINT,
            requested_events VARCHAR,
            returned_events VARCHAR
        );

        CREATE TABLE IF NOT EXISTS clock_snapshot (
            trace_id VARCHAR,
            clock_id INTEGER,
            clock_name VARCHAR,
            timestamp_ns BIGINT,
            is_primary BOOLEAN
        );
        ",
    )?;

    Ok(())
}

/// Import Parquet files from a directory into a DuckDB database.
///
/// This function creates a new DuckDB database at `db_path` and imports
/// all Parquet files from `parquet_dir`. Each table gets a `trace_id` column
/// added for multi-trace support.
///
/// # Arguments
///
/// * `parquet_dir` - Directory containing .parquet files (output from `systing record`)
/// * `db_path` - Output path for the DuckDB database
/// * `trace_id` - Identifier for this trace (used in trace_id column)
///
/// # Example
///
/// ```no_run
/// use systing::duckdb::parquet_to_duckdb;
/// use std::path::Path;
///
/// parquet_to_duckdb(
///     Path::new("./traces"),
///     Path::new("./trace.duckdb"),
///     "my_trace",
/// ).unwrap();
/// ```
pub fn parquet_to_duckdb(parquet_dir: &Path, db_path: &Path, trace_id: &str) -> Result<()> {
    // Remove existing database if present
    if db_path.exists() {
        std::fs::remove_file(db_path).with_context(|| {
            format!("Failed to remove existing database: {}", db_path.display())
        })?;
    }

    let conn = Connection::open(db_path)
        .with_context(|| format!("Failed to create DuckDB database: {}", db_path.display()))?;

    // Configure DuckDB for parallel import.
    // Use a conservative default of 4 threads if CPU count detection fails.
    let num_cpus = std::thread::available_parallelism()
        .map(|n| n.get())
        .unwrap_or(4);
    conn.execute_batch(&format!("SET threads TO {num_cpus};"))?;

    create_schema(&conn)?;

    // Insert trace metadata
    conn.execute(
        "INSERT INTO _traces (trace_id, source_path) VALUES (?, ?)",
        [trace_id, &parquet_dir.to_string_lossy()],
    )?;

    // Import each table from Parquet files
    let paths = ParquetPaths::new(parquet_dir);
    import_tables(&conn, &paths, trace_id)?;

    Ok(())
}

/// Import all tables from Parquet files.
fn import_tables(conn: &Connection, paths: &ParquetPaths, trace_id: &str) -> Result<()> {
    // Helper to import a single table with trace_id injection.
    //
    // Note on SQL safety: We use string interpolation here because DuckDB's execute_batch
    // does not support parameterized queries. The escaping (replacing ' with '') is the
    // standard SQL escape for single quotes and is safe for the path and trace_id values
    // we're inserting. The table_name is always a literal from this code, not user input.
    let import_table = |table_name: &str, path: &Path| -> Result<()> {
        if !path.exists() {
            return Ok(());
        }

        let escaped_path = path.to_string_lossy().replace('\'', "''");
        let escaped_trace_id = trace_id.replace('\'', "''");

        conn.execute_batch(&format!(
            "INSERT INTO {table_name} SELECT '{escaped_trace_id}' as trace_id, * FROM read_parquet('{escaped_path}')"
        ))
        .with_context(|| format!("Failed to import table '{}' from '{}'", table_name, path.display()))?;

        Ok(())
    };

    // Import core tables
    import_table("process", &paths.process)?;
    import_table("thread", &paths.thread)?;
    import_table("sched_slice", &paths.sched_slice)?;
    import_table("thread_state", &paths.thread_state)?;

    // IRQ/softirq tables
    import_table("irq_slice", &paths.irq_slice)?;
    import_table("softirq_slice", &paths.softirq_slice)?;
    import_table("wakeup_new", &paths.wakeup_new)?;
    import_table("process_exit", &paths.process_exit)?;

    // Counter tables
    import_table("counter_track", &paths.counter_track)?;
    import_table("counter", &paths.counter)?;

    // Event tables
    import_table("slice", &paths.slice)?;
    import_table("track", &paths.track)?;
    import_table("args", &paths.args)?;
    import_table("instant", &paths.instant)?;
    import_table("instant_args", &paths.instant_args)?;

    // Stack tables (query-friendly format)
    import_table("stack", &paths.stack)?;
    import_table("stack_sample", &paths.stack_sample)?;

    // Legacy stack profile tables (for Perfetto .pb extraction compatibility)
    import_table("stack_profile_symbol", &paths.symbol)?;
    import_table("stack_profile_mapping", &paths.stack_mapping)?;
    import_table("stack_profile_frame", &paths.frame)?;
    import_table("stack_profile_callsite", &paths.callsite)?;
    import_table("perf_sample", &paths.perf_sample)?;

    // Network tables
    import_table("network_interface", &paths.network_interface)?;
    import_table("socket_connection", &paths.socket_connection)?;
    import_table("network_syscall", &paths.network_syscall)?;
    import_table("network_packet", &paths.network_packet)?;
    import_table("network_socket", &paths.network_socket)?;
    import_table("network_poll", &paths.network_poll)?;

    // Clock snapshot
    import_table("clock_snapshot", &paths.clock_snapshot)?;

    Ok(())
}

#[cfg(test)]
mod tests {
    use super::*;
    use std::fs;
    use tempfile::TempDir;

    #[test]
    fn test_create_schema() {
        let temp_dir = TempDir::new().unwrap();
        let db_path = temp_dir.path().join("test.duckdb");

        let conn = Connection::open(&db_path).unwrap();
        create_schema(&conn).unwrap();

        // Verify some key tables exist
        let tables: Vec<String> = conn
            .prepare("SELECT table_name FROM information_schema.tables WHERE table_schema = 'main'")
            .unwrap()
            .query_map([], |row| row.get(0))
            .unwrap()
            .filter_map(|r| r.ok())
            .collect();

        assert!(tables.contains(&"process".to_string()));
        assert!(tables.contains(&"thread".to_string()));
        assert!(tables.contains(&"sched_slice".to_string()));
        assert!(tables.contains(&"stack".to_string()));
    }

    #[test]
    fn test_parquet_to_duckdb_empty_dir() {
        let temp_dir = TempDir::new().unwrap();
        let parquet_dir = temp_dir.path().join("traces");
        fs::create_dir(&parquet_dir).unwrap();

        let db_path = temp_dir.path().join("test.duckdb");

        // Should succeed even with no parquet files
        parquet_to_duckdb(&parquet_dir, &db_path, "test_trace").unwrap();

        // Verify database was created
        assert!(db_path.exists());

        // Verify trace was recorded
        let conn = Connection::open(&db_path).unwrap();
        let count: i64 = conn
            .query_row("SELECT COUNT(*) FROM _traces", [], |row| row.get(0))
            .unwrap();
        assert_eq!(count, 1);
    }
}
