//! DuckDB database generation from Parquet files.
//!
//! This module provides functionality for creating DuckDB databases from
//! Parquet trace files generated by systing.

use anyhow::{Context, Result};
use duckdb::Connection;
use std::path::Path;

use crate::parquet_paths::ParquetPaths;

/// Create DuckDB schema with all tables.
///
/// Creates tables for:
/// - Process and thread metadata
/// - Scheduler events (sched_slice, thread_state, IRQ, softirq)
/// - Events (slice, track, instant, args)
/// - Performance counters
/// - Stack traces (both legacy and query-friendly formats)
/// - Network events
/// - Clock snapshots
pub fn create_schema(conn: &Connection) -> Result<()> {
    conn.execute_batch(
        "
        CREATE TABLE IF NOT EXISTS _traces (
            trace_id VARCHAR PRIMARY KEY,
            source_path VARCHAR,
            import_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        );

        CREATE TABLE IF NOT EXISTS process (
            trace_id VARCHAR,
            upid BIGINT,
            pid INTEGER,
            name VARCHAR,
            parent_upid BIGINT,
            cmdline VARCHAR[]
        );

        CREATE TABLE IF NOT EXISTS thread (
            trace_id VARCHAR,
            utid BIGINT,
            tid INTEGER,
            name VARCHAR,
            upid BIGINT
        );

        CREATE TABLE IF NOT EXISTS sched_slice (
            trace_id VARCHAR,
            ts BIGINT,
            dur BIGINT,
            cpu INTEGER,
            utid BIGINT,
            end_state INTEGER,
            priority INTEGER
        );

        CREATE TABLE IF NOT EXISTS thread_state (
            trace_id VARCHAR,
            ts BIGINT,
            dur BIGINT,
            utid BIGINT,
            state INTEGER,
            cpu INTEGER
        );

        CREATE TABLE IF NOT EXISTS irq_slice (
            trace_id VARCHAR,
            ts BIGINT,
            dur BIGINT,
            cpu INTEGER,
            irq INTEGER,
            name VARCHAR,
            ret INTEGER
        );

        CREATE TABLE IF NOT EXISTS softirq_slice (
            trace_id VARCHAR,
            ts BIGINT,
            dur BIGINT,
            cpu INTEGER,
            vec INTEGER
        );

        CREATE TABLE IF NOT EXISTS wakeup_new (
            trace_id VARCHAR,
            ts BIGINT,
            cpu INTEGER,
            utid BIGINT,
            target_cpu INTEGER
        );

        CREATE TABLE IF NOT EXISTS process_exit (
            trace_id VARCHAR,
            ts BIGINT,
            cpu INTEGER,
            utid BIGINT
        );

        CREATE TABLE IF NOT EXISTS counter_track (
            trace_id VARCHAR,
            id BIGINT,
            name VARCHAR,
            unit VARCHAR
        );

        CREATE TABLE IF NOT EXISTS counter (
            trace_id VARCHAR,
            ts BIGINT,
            track_id BIGINT,
            value DOUBLE
        );

        CREATE TABLE IF NOT EXISTS slice (
            trace_id VARCHAR,
            id BIGINT,
            ts BIGINT,
            dur BIGINT,
            track_id BIGINT,
            utid BIGINT,
            name VARCHAR,
            category VARCHAR,
            depth INTEGER
        );

        CREATE TABLE IF NOT EXISTS track (
            trace_id VARCHAR,
            id BIGINT,
            name VARCHAR,
            parent_id BIGINT
        );

        CREATE TABLE IF NOT EXISTS args (
            trace_id VARCHAR,
            slice_id BIGINT,
            key VARCHAR,
            int_value BIGINT,
            string_value VARCHAR,
            real_value DOUBLE
        );

        CREATE TABLE IF NOT EXISTS instant (
            trace_id VARCHAR,
            id BIGINT,
            ts BIGINT,
            track_id BIGINT,
            utid BIGINT,
            name VARCHAR,
            category VARCHAR
        );

        CREATE TABLE IF NOT EXISTS instant_args (
            trace_id VARCHAR,
            instant_id BIGINT,
            key VARCHAR,
            int_value BIGINT,
            string_value VARCHAR,
            real_value DOUBLE
        );

        -- Legacy stack trace tables (for Perfetto .pb file conversion)
        CREATE TABLE IF NOT EXISTS stack_profile_symbol (
            trace_id VARCHAR,
            id BIGINT,
            name VARCHAR
        );

        CREATE TABLE IF NOT EXISTS stack_profile_mapping (
            trace_id VARCHAR,
            id BIGINT,
            build_id VARCHAR,
            name VARCHAR,
            exact_offset BIGINT,
            start_offset BIGINT
        );

        CREATE TABLE IF NOT EXISTS stack_profile_frame (
            trace_id VARCHAR,
            id BIGINT,
            name VARCHAR,
            mapping_id BIGINT,
            rel_pc BIGINT,
            symbol_id BIGINT
        );

        CREATE TABLE IF NOT EXISTS stack_profile_callsite (
            trace_id VARCHAR,
            id BIGINT,
            parent_id BIGINT,
            frame_id BIGINT,
            depth INTEGER
        );

        CREATE TABLE IF NOT EXISTS perf_sample (
            trace_id VARCHAR,
            ts BIGINT,
            utid BIGINT,
            callsite_id BIGINT,
            cpu INTEGER
        );

        -- Query-friendly stack tables (new schema)
        CREATE TABLE IF NOT EXISTS stack (
            trace_id VARCHAR,
            id BIGINT,
            frame_names VARCHAR[],
            depth INTEGER,
            leaf_name VARCHAR
        );

        CREATE TABLE IF NOT EXISTS stack_sample (
            trace_id VARCHAR,
            ts BIGINT,
            utid BIGINT,
            cpu INTEGER,
            stack_id BIGINT,
            stack_event_type TINYINT
        );

        -- Network interface metadata
        CREATE TABLE IF NOT EXISTS network_interface (
            trace_id VARCHAR,
            namespace VARCHAR,
            interface_name VARCHAR,
            ip_address VARCHAR,
            address_type VARCHAR
        );

        -- Socket connection metadata (extracted from socket track names)
        CREATE TABLE IF NOT EXISTS socket_connection (
            trace_id VARCHAR,
            socket_id BIGINT,
            track_id BIGINT,
            protocol VARCHAR,
            src_ip VARCHAR,
            src_port INTEGER,
            dest_ip VARCHAR,
            dest_port INTEGER,
            address_family VARCHAR
        );

        -- New network tables (Phase 1 of network recorder refactor)
        CREATE TABLE IF NOT EXISTS network_syscall (
            trace_id VARCHAR,
            id BIGINT,
            ts BIGINT,
            dur BIGINT,
            tid INTEGER,
            pid INTEGER,
            event_type VARCHAR,
            socket_id BIGINT,
            bytes BIGINT,
            seq BIGINT,
            sndbuf_used BIGINT,
            sndbuf_limit BIGINT,
            sndbuf_fill_pct SMALLINT,
            recv_seq_start BIGINT,
            recv_seq_end BIGINT,
            rcv_nxt BIGINT,
            bytes_available BIGINT
        );

        CREATE TABLE IF NOT EXISTS network_packet (
            trace_id VARCHAR,
            id BIGINT,
            ts BIGINT,
            socket_id BIGINT,
            event_type VARCHAR,
            seq BIGINT,
            length INTEGER,
            tcp_flags VARCHAR,
            -- Send buffer fields
            sndbuf_used BIGINT,
            sndbuf_limit BIGINT,
            sndbuf_fill_pct SMALLINT,
            -- Retransmit fields
            is_retransmit BOOLEAN,
            retransmit_count SMALLINT,
            rto_ms INTEGER,
            srtt_ms INTEGER,
            rttvar_us INTEGER,
            backoff SMALLINT,
            -- Zero window fields
            is_zero_window_probe BOOLEAN,
            is_zero_window_ack BOOLEAN,
            probe_count SMALLINT,
            -- Window fields
            snd_wnd INTEGER,
            rcv_wnd INTEGER,
            rcv_buf_used BIGINT,
            rcv_buf_limit BIGINT,
            window_clamp INTEGER,
            rcv_wscale SMALLINT,
            -- Timer fields
            icsk_pending SMALLINT,
            icsk_timeout BIGINT,
            -- Drop fields
            drop_reason INTEGER,
            drop_reason_str VARCHAR,
            drop_location BIGINT,
            -- Queue fields
            qlen INTEGER,
            qlen_limit INTEGER,
            -- TSQ fields
            sk_wmem_alloc BIGINT,
            tsq_limit BIGINT,
            -- TX queue fields
            txq_state INTEGER,
            qdisc_state INTEGER,
            qdisc_backlog BIGINT,
            -- SKB correlation
            skb_addr BIGINT,
            qdisc_latency_us INTEGER
        );

        CREATE TABLE IF NOT EXISTS network_socket (
            trace_id VARCHAR,
            socket_id BIGINT,
            protocol VARCHAR,
            address_family VARCHAR,
            src_ip VARCHAR,
            src_port INTEGER,
            dest_ip VARCHAR,
            dest_port INTEGER,
            first_seen_ts BIGINT,
            last_seen_ts BIGINT
        );

        CREATE TABLE IF NOT EXISTS network_poll (
            trace_id VARCHAR,
            id BIGINT,
            ts BIGINT,
            tid INTEGER,
            pid INTEGER,
            socket_id BIGINT,
            requested_events VARCHAR,
            returned_events VARCHAR
        );

        CREATE TABLE IF NOT EXISTS clock_snapshot (
            trace_id VARCHAR,
            clock_id INTEGER,
            clock_name VARCHAR,
            timestamp_ns BIGINT,
            is_primary BOOLEAN
        );

        CREATE TABLE IF NOT EXISTS sysinfo (
            trace_id VARCHAR,
            sysname VARCHAR,
            release VARCHAR,
            version VARCHAR,
            machine VARCHAR
        );
        ",
    )?;

    Ok(())
}

/// Import Parquet files from a directory into a DuckDB database.
///
/// This function creates a new DuckDB database at `db_path` and imports
/// all Parquet files from `parquet_dir`. Each table gets a `trace_id` column
/// added for multi-trace support.
///
/// # Arguments
///
/// * `parquet_dir` - Directory containing .parquet files (output from `systing record`)
/// * `db_path` - Output path for the DuckDB database
/// * `trace_id` - Identifier for this trace (used in trace_id column)
///
/// # Example
///
/// ```no_run
/// use systing::duckdb::parquet_to_duckdb;
/// use std::path::Path;
///
/// parquet_to_duckdb(
///     Path::new("./traces"),
///     Path::new("./trace.duckdb"),
///     "my_trace",
/// ).unwrap();
/// ```
pub fn parquet_to_duckdb(parquet_dir: &Path, db_path: &Path, trace_id: &str) -> Result<()> {
    // Remove existing database if present
    if db_path.exists() {
        std::fs::remove_file(db_path).with_context(|| {
            format!("Failed to remove existing database: {}", db_path.display())
        })?;
    }

    let conn = Connection::open(db_path)
        .with_context(|| format!("Failed to create DuckDB database: {}", db_path.display()))?;

    // Configure DuckDB for parallel import.
    // Use a conservative default of 4 threads if CPU count detection fails.
    let num_cpus = std::thread::available_parallelism()
        .map(|n| n.get())
        .unwrap_or(4);
    conn.execute_batch(&format!("SET threads TO {num_cpus};"))?;

    create_schema(&conn)?;

    // Insert trace metadata
    conn.execute(
        "INSERT INTO _traces (trace_id, source_path) VALUES (?, ?)",
        [trace_id, &parquet_dir.to_string_lossy()],
    )?;

    // Import each table from Parquet files
    let paths = ParquetPaths::new(parquet_dir);
    import_tables(&conn, &paths, trace_id)?;

    Ok(())
}

/// Import all tables from Parquet files.
fn import_tables(conn: &Connection, paths: &ParquetPaths, trace_id: &str) -> Result<()> {
    // Helper to import a single table with trace_id injection.
    //
    // Note on SQL safety: We use string interpolation here because DuckDB's execute_batch
    // does not support parameterized queries. The escaping (replacing ' with '') is the
    // standard SQL escape for single quotes and is safe for the path and trace_id values
    // we're inserting. The table_name is always a literal from this code, not user input.
    let import_table = |table_name: &str, path: &Path| -> Result<()> {
        if !path.exists() {
            return Ok(());
        }

        let escaped_path = path.to_string_lossy().replace('\'', "''");
        let escaped_trace_id = trace_id.replace('\'', "''");

        conn.execute_batch(&format!(
            "INSERT INTO {table_name} SELECT '{escaped_trace_id}' as trace_id, * FROM read_parquet('{escaped_path}')"
        ))
        .with_context(|| format!("Failed to import table '{}' from '{}'", table_name, path.display()))?;

        Ok(())
    };

    // Import core tables
    import_table("process", &paths.process)?;
    import_table("thread", &paths.thread)?;
    import_table("sched_slice", &paths.sched_slice)?;
    import_table("thread_state", &paths.thread_state)?;

    // IRQ/softirq tables
    import_table("irq_slice", &paths.irq_slice)?;
    import_table("softirq_slice", &paths.softirq_slice)?;
    import_table("wakeup_new", &paths.wakeup_new)?;
    import_table("process_exit", &paths.process_exit)?;

    // Counter tables
    import_table("counter_track", &paths.counter_track)?;
    import_table("counter", &paths.counter)?;

    // Event tables
    import_table("slice", &paths.slice)?;
    import_table("track", &paths.track)?;
    import_table("args", &paths.args)?;
    import_table("instant", &paths.instant)?;
    import_table("instant_args", &paths.instant_args)?;

    // Stack tables (query-friendly format)
    import_table("stack", &paths.stack)?;
    import_table("stack_sample", &paths.stack_sample)?;

    // Legacy stack profile tables (for Perfetto .pb extraction compatibility)
    import_table("stack_profile_symbol", &paths.symbol)?;
    import_table("stack_profile_mapping", &paths.stack_mapping)?;
    import_table("stack_profile_frame", &paths.frame)?;
    import_table("stack_profile_callsite", &paths.callsite)?;
    import_table("perf_sample", &paths.perf_sample)?;

    // Network tables
    import_table("network_interface", &paths.network_interface)?;
    import_table("socket_connection", &paths.socket_connection)?;
    import_table("network_syscall", &paths.network_syscall)?;
    import_table("network_packet", &paths.network_packet)?;
    import_table("network_socket", &paths.network_socket)?;
    import_table("network_poll", &paths.network_poll)?;

    // Clock snapshot
    import_table("clock_snapshot", &paths.clock_snapshot)?;

    // System info
    import_table("sysinfo", &paths.sysinfo)?;

    Ok(())
}

/// Get list of trace IDs in a DuckDB database.
///
/// Returns a vector of trace IDs found in the _traces table.
///
/// # Arguments
///
/// * `db_path` - Path to the DuckDB database file
///
/// # Example
///
/// ```no_run
/// use systing::duckdb::get_trace_ids;
/// use std::path::Path;
///
/// let trace_ids = get_trace_ids(Path::new("./trace.duckdb")).unwrap();
/// for id in trace_ids {
///     println!("Found trace: {}", id);
/// }
/// ```
pub fn get_trace_ids(db_path: &Path) -> Result<Vec<String>> {
    let conn = Connection::open(db_path)
        .with_context(|| format!("Failed to open DuckDB database: {}", db_path.display()))?;

    let mut stmt = conn
        .prepare("SELECT trace_id FROM _traces ORDER BY trace_id")
        .with_context(|| "Failed to query _traces table - database may not be a systing trace")?;

    let trace_ids: Vec<String> = stmt
        .query_map([], |row| row.get(0))
        .with_context(|| "Failed to execute query on _traces table")?
        .filter_map(|r| r.ok())
        .collect();

    Ok(trace_ids)
}

/// Export DuckDB tables to Parquet files.
///
/// This function exports all trace tables from a DuckDB database to Parquet files
/// in the specified output directory. The trace_id column is excluded from the
/// output since Parquet files don't use it.
///
/// # Arguments
///
/// * `db_path` - Path to the source DuckDB database
/// * `output_dir` - Directory where Parquet files will be written
/// * `trace_id` - The trace ID to export (must exist in the database)
///
/// # Example
///
/// ```no_run
/// use systing::duckdb::duckdb_to_parquet;
/// use std::path::Path;
///
/// duckdb_to_parquet(
///     Path::new("./trace.duckdb"),
///     Path::new("./parquet_output"),
///     "my_trace",
/// ).unwrap();
/// ```
pub fn duckdb_to_parquet(db_path: &Path, output_dir: &Path, trace_id: &str) -> Result<()> {
    let conn = Connection::open(db_path)
        .with_context(|| format!("Failed to open DuckDB database: {}", db_path.display()))?;

    // Create output directory if it doesn't exist
    std::fs::create_dir_all(output_dir).with_context(|| {
        format!(
            "Failed to create output directory: {}",
            output_dir.display()
        )
    })?;

    // Configure DuckDB for parallel export
    let num_cpus = std::thread::available_parallelism()
        .map(|n| n.get())
        .unwrap_or(4);
    conn.execute_batch(&format!("SET threads TO {num_cpus};"))?;

    let paths = ParquetPaths::new(output_dir);
    let escaped_trace_id = trace_id.replace('\'', "''");

    // Helper to export a single table to Parquet
    // Uses EXCLUDE to omit the trace_id column (Parquet files don't have it)
    let export_table = |table_name: &str, output_path: &Path| -> Result<()> {
        // First check if the table has any rows for this trace_id
        let count_query =
            format!("SELECT COUNT(*) FROM {table_name} WHERE trace_id = '{escaped_trace_id}'");
        let count: i64 = conn
            .query_row(&count_query, [], |row| row.get(0))
            .unwrap_or(0);

        if count == 0 {
            // Skip empty tables
            return Ok(());
        }

        let escaped_path = output_path.to_string_lossy().replace('\'', "''");
        let query = format!(
            "COPY (SELECT * EXCLUDE (trace_id) FROM {table_name} WHERE trace_id = '{escaped_trace_id}') \
             TO '{escaped_path}' (FORMAT PARQUET, COMPRESSION ZSTD)"
        );

        conn.execute_batch(&query).with_context(|| {
            format!(
                "Failed to export table '{}' to '{}'",
                table_name,
                output_path.display()
            )
        })?;

        Ok(())
    };

    // Export all tables
    export_table("process", &paths.process)?;
    export_table("thread", &paths.thread)?;
    export_table("sched_slice", &paths.sched_slice)?;
    export_table("thread_state", &paths.thread_state)?;

    // IRQ/softirq tables
    export_table("irq_slice", &paths.irq_slice)?;
    export_table("softirq_slice", &paths.softirq_slice)?;
    export_table("wakeup_new", &paths.wakeup_new)?;
    export_table("process_exit", &paths.process_exit)?;

    // Counter tables
    export_table("counter_track", &paths.counter_track)?;
    export_table("counter", &paths.counter)?;

    // Event tables
    export_table("slice", &paths.slice)?;
    export_table("track", &paths.track)?;
    export_table("args", &paths.args)?;
    export_table("instant", &paths.instant)?;
    export_table("instant_args", &paths.instant_args)?;

    // Stack tables (query-friendly format)
    export_table("stack", &paths.stack)?;
    export_table("stack_sample", &paths.stack_sample)?;

    // Legacy stack profile tables (for Perfetto .pb extraction compatibility)
    export_table("stack_profile_symbol", &paths.symbol)?;
    export_table("stack_profile_mapping", &paths.stack_mapping)?;
    export_table("stack_profile_frame", &paths.frame)?;
    export_table("stack_profile_callsite", &paths.callsite)?;
    export_table("perf_sample", &paths.perf_sample)?;

    // Network tables
    export_table("network_interface", &paths.network_interface)?;
    export_table("socket_connection", &paths.socket_connection)?;
    export_table("network_syscall", &paths.network_syscall)?;
    export_table("network_packet", &paths.network_packet)?;
    export_table("network_socket", &paths.network_socket)?;
    export_table("network_poll", &paths.network_poll)?;

    // Clock snapshot
    export_table("clock_snapshot", &paths.clock_snapshot)?;

    // System info
    export_table("sysinfo", &paths.sysinfo)?;

    Ok(())
}

#[cfg(test)]
mod tests {
    use super::*;
    use std::fs;
    use tempfile::TempDir;

    #[test]
    fn test_create_schema() {
        let temp_dir = TempDir::new().unwrap();
        let db_path = temp_dir.path().join("test.duckdb");

        let conn = Connection::open(&db_path).unwrap();
        create_schema(&conn).unwrap();

        // Verify some key tables exist
        let tables: Vec<String> = conn
            .prepare("SELECT table_name FROM information_schema.tables WHERE table_schema = 'main'")
            .unwrap()
            .query_map([], |row| row.get(0))
            .unwrap()
            .filter_map(|r| r.ok())
            .collect();

        assert!(tables.contains(&"process".to_string()));
        assert!(tables.contains(&"thread".to_string()));
        assert!(tables.contains(&"sched_slice".to_string()));
        assert!(tables.contains(&"stack".to_string()));
    }

    #[test]
    fn test_parquet_to_duckdb_empty_dir() {
        let temp_dir = TempDir::new().unwrap();
        let parquet_dir = temp_dir.path().join("traces");
        fs::create_dir(&parquet_dir).unwrap();

        let db_path = temp_dir.path().join("test.duckdb");

        // Should succeed even with no parquet files
        parquet_to_duckdb(&parquet_dir, &db_path, "test_trace").unwrap();

        // Verify database was created
        assert!(db_path.exists());

        // Verify trace was recorded
        let conn = Connection::open(&db_path).unwrap();
        let count: i64 = conn
            .query_row("SELECT COUNT(*) FROM _traces", [], |row| row.get(0))
            .unwrap();
        assert_eq!(count, 1);
    }

    #[test]
    fn test_get_trace_ids() {
        let temp_dir = TempDir::new().unwrap();
        let parquet_dir = temp_dir.path().join("traces");
        fs::create_dir(&parquet_dir).unwrap();

        let db_path = temp_dir.path().join("test.duckdb");

        // Create a database with a trace
        parquet_to_duckdb(&parquet_dir, &db_path, "my_trace_id").unwrap();

        // Get trace IDs
        let trace_ids = get_trace_ids(&db_path).unwrap();

        assert_eq!(trace_ids.len(), 1);
        assert_eq!(trace_ids[0], "my_trace_id");
    }

    #[test]
    fn test_get_trace_ids_multiple() {
        let temp_dir = TempDir::new().unwrap();
        let db_path = temp_dir.path().join("test.duckdb");

        // Create database and add multiple traces manually
        let conn = Connection::open(&db_path).unwrap();
        create_schema(&conn).unwrap();
        conn.execute(
            "INSERT INTO _traces (trace_id, source_path) VALUES (?, ?)",
            ["trace_a", "/path/a"],
        )
        .unwrap();
        conn.execute(
            "INSERT INTO _traces (trace_id, source_path) VALUES (?, ?)",
            ["trace_b", "/path/b"],
        )
        .unwrap();
        drop(conn);

        // Get trace IDs
        let trace_ids = get_trace_ids(&db_path).unwrap();

        assert_eq!(trace_ids.len(), 2);
        assert!(trace_ids.contains(&"trace_a".to_string()));
        assert!(trace_ids.contains(&"trace_b".to_string()));
    }

    #[test]
    fn test_duckdb_to_parquet_roundtrip() {
        let temp_dir = TempDir::new().unwrap();
        let db_path = temp_dir.path().join("test.duckdb");
        let output_dir = temp_dir.path().join("output");

        // Create a database with some test data
        let conn = Connection::open(&db_path).unwrap();
        create_schema(&conn).unwrap();
        conn.execute(
            "INSERT INTO _traces (trace_id, source_path) VALUES (?, ?)",
            ["test_trace", "/test/path"],
        )
        .unwrap();
        conn.execute(
            "INSERT INTO process (trace_id, upid, pid, name) VALUES (?, ?, ?, ?)",
            duckdb::params!["test_trace", 1i64, 1234i32, "test_process"],
        )
        .unwrap();
        conn.execute(
            "INSERT INTO thread (trace_id, utid, tid, name, upid) VALUES (?, ?, ?, ?, ?)",
            duckdb::params!["test_trace", 1i64, 1234i32, "main", 1i64],
        )
        .unwrap();
        drop(conn);

        // Export to Parquet
        duckdb_to_parquet(&db_path, &output_dir, "test_trace").unwrap();

        // Verify Parquet files were created
        assert!(output_dir.join("process.parquet").exists());
        assert!(output_dir.join("thread.parquet").exists());

        // Verify the Parquet files can be read back
        use parquet::arrow::arrow_reader::ParquetRecordBatchReaderBuilder;
        use std::fs::File;

        let file = File::open(output_dir.join("process.parquet")).unwrap();
        let builder = ParquetRecordBatchReaderBuilder::try_new(file).unwrap();
        let reader = builder.build().unwrap();

        let mut total_rows = 0;
        for batch in reader {
            let batch = batch.unwrap();
            total_rows += batch.num_rows();
        }
        assert_eq!(total_rows, 1, "Expected 1 process row");
    }
}
