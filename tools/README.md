# Perfetto Trace Analysis Tools

This directory contains tools for analyzing Perfetto trace files generated by systing using SQL-based queries via `trace_processor`.

## Prerequisites

Install `trace_processor` from Perfetto:
- Download from https://perfetto.dev/docs/quickstart/trace-analysis
- Or build from source: https://github.com/google/perfetto

## analyze_trace.py

A comprehensive Python script that analyzes systing Perfetto traces and produces summaries suitable for LLM analysis (Claude, etc.) or human review.

### Usage

```bash
# Print markdown summary to stdout
./analyze_trace.py trace.pb

# Print JSON summary
./analyze_trace.py trace.pb --format json

# Save to file
./analyze_trace.py trace.pb -o summary.md

# Save JSON to file
./analyze_trace.py trace.pb --format json -o summary.json
```

### What it Analyzes

- **Overview**: Duration, CPU count, process/thread counts, total context switches
- **Scheduling Latency**: System-wide latency statistics with percentiles (p50, p95, p99)
- **Per-CPU Statistics**: Context switches, latency per CPU
- **Process/Thread Latency**: Top processes and threads by scheduling latency
- **Blocking Analysis**: Long blocking events (>10ms), processes with high blocking time
- **CPU Hotspots**: Top functions by sample count, CPU time by process/thread
- **Sleep Stack Analysis**: Stack traces weighted by actual sleep time (not just sample count)
- **Counters**: Runqueue stats, performance counters
- **Custom Events**: Events from `--trace-event` flag
- **Anomaly Detection**: Flags potential issues like high latency, CPU imbalance

### Output Formats

**Markdown** (default): Human-readable tables and formatted sections, ideal for pasting into documents or sharing with LLMs.

**JSON**: Machine-readable structured data, ideal for further processing or integration with other tools.

## trace_queries.sql

A collection of SQL queries for manual/interactive trace analysis. Use these when you need more control or want to explore specific aspects of a trace.

### Usage

Run all queries at once:
```bash
trace_processor trace.pb -q trace_queries.sql
```

Interactive mode (recommended for exploration):
```bash
trace_processor trace.pb

# Then inside the shell:
.read trace_queries.sql
```

Or run individual queries interactively:
```bash
trace_processor trace.pb

# Example: top processes by latency
SELECT p.name, p.pid, MAX(s.dur)/1e6 as max_ms
FROM sched_slice s
JOIN thread t ON s.utid = t.utid
JOIN process p ON t.upid = p.upid
GROUP BY p.pid ORDER BY max_ms DESC LIMIT 10;
```

### Query Categories

The SQL file includes queries for:

1. **Scheduling Latency Analysis**
   - System-wide latency percentiles
   - Per-CPU scheduling statistics
   - Top processes/threads by latency

2. **Blocking/Sleep Analysis**
   - Long blocking events (>10ms)
   - Blocking grouped by process/thread
   - Latency histogram by duration buckets

3. **CPU/Stack Trace Analysis**
   - Top functions by CPU sample count
   - Kernel vs userspace breakdown
   - CPU time by process/thread

4. **Sleep-Weighted Stack Analysis** (key for finding bottlenecks)
   - Stacks weighted by actual sleep time, not sample count
   - Uninterruptible sleep (D-state) analysis
   - Full stack trace reconstruction

5. **Custom Events/Slices**
   - Summary of slice events from `--trace-event`
   - Slowest individual events

6. **Counter Analysis**
   - Runqueue size statistics
   - All counter tracks with summary stats

7. **Time-Series Analysis**
   - Latency over time (1-second buckets)
   - Per-CPU utilization over time

8. **Anomaly Detection**
   - Scheduling spikes (>5x average)
   - Potential lock contention detection

### Key Query: Sleep-Weighted Stack Analysis

The most important query for finding blocking bottlenecks:

```sql
WITH sleep_weighted AS (
    SELECT
        ps.callsite_id,
        ts.state,
        SUM(ts.dur) / 1e6 as total_sleep_ms,
        COUNT(*) as samples,
        MAX(ts.dur) / 1e6 as max_sleep_ms
    FROM perf_sample ps
    JOIN thread_state ts ON ps.utid = ts.utid
        AND ps.ts >= ts.ts
        AND ps.ts < ts.ts + ts.dur
    WHERE ts.state IN ('S', 'D')
    GROUP BY ps.callsite_id, ts.state
)
SELECT callsite_id, state, total_sleep_ms, samples, max_sleep_ms
FROM sleep_weighted
WHERE total_sleep_ms > 1
ORDER BY total_sleep_ms DESC
LIMIT 30;
```

This weights stack traces by the actual time spent sleeping/blocking, not just how often they were sampled. This is critical for identifying the true bottlenecks.

## Tips

### For LLM Analysis

Generate a markdown summary and paste it into Claude or another LLM:
```bash
./analyze_trace.py trace.pb | pbcopy  # macOS
./analyze_trace.py trace.pb | xclip   # Linux
```

### For Programmatic Analysis

Use JSON output for scripting:
```bash
./analyze_trace.py trace.pb --format json | jq '.top_cpu_stacks[:5]'
```

### For Deep Investigation

Use `trace_processor` interactively to run custom queries:
```bash
trace_processor trace.pb
```

### Understanding Stack Traces

Systing stores stack traces in `stack_profile_callsite` and `stack_profile_frame` tables. Use the recursive stack walk query in `trace_queries.sql` to reconstruct full call chains from a `callsite_id`.
