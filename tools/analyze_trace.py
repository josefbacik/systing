#!/usr/bin/env python3
"""
Systing Trace Analyzer

Analyzes Perfetto trace files generated by systing and produces
summaries suitable for LLM analysis (Claude, etc.)

Usage:
    ./analyze_trace.py trace.pb [--format json|markdown] [--output summary.md]

Requirements:
    - trace_processor (from Perfetto)
    - Python 3.8+
"""

import argparse
import json
import subprocess
import sys
import tempfile
import os
from dataclasses import dataclass, field, asdict
from typing import Optional, List
from pathlib import Path


@dataclass
class LatencyStats:
    count: int = 0
    min_us: float = 0
    max_us: float = 0
    avg_us: float = 0
    p50_us: float = 0
    p95_us: float = 0
    p99_us: float = 0
    total_us: float = 0


@dataclass
class ProcessStats:
    name: str = ""
    pid: int = 0
    tid: int = 0
    thread_name: str = ""
    samples: int = 0
    latency: LatencyStats = field(default_factory=LatencyStats)
    cpu_pct: float = 0


@dataclass
class StackTrace:
    stack: str = ""
    count: int = 0
    total_time_us: float = 0
    avg_time_us: float = 0
    pct_of_total: float = 0


@dataclass
class TraceSummary:
    # Overview
    duration_sec: float = 0
    num_cpus: int = 0
    num_processes: int = 0
    num_threads: int = 0

    # Scheduling
    total_context_switches: int = 0
    system_latency: LatencyStats = field(default_factory=LatencyStats)
    per_cpu_stats: list = field(default_factory=list)
    top_processes_by_latency: list = field(default_factory=list)
    top_threads_by_latency: list = field(default_factory=list)

    # Sleep/blocking analysis
    top_sleep_stacks: list = field(default_factory=list)
    long_sleep_events: list = field(default_factory=list)
    uninterruptible_sleep_stacks: list = field(default_factory=list)

    # CPU analysis
    top_cpu_stacks: list = field(default_factory=list)
    cpu_hotspots_by_process: list = field(default_factory=list)
    cpu_hotspots_by_thread: list = field(default_factory=list)

    # Counters
    perf_counters: list = field(default_factory=list)
    runqueue_stats: list = field(default_factory=list)

    # Custom events
    custom_events: list = field(default_factory=list)

    # Anomalies
    anomalies: list = field(default_factory=list)


class TraceProcessor:
    """Wrapper around trace_processor"""

    def __init__(self, trace_path: str):
        self.trace_path = trace_path
        self.tp_path = self._find_trace_processor()

    def _find_trace_processor(self) -> str:
        """Find trace_processor in PATH or common locations"""
        # Check PATH first
        for name in ['trace_processor', 'trace_processor_shell']:
            result = subprocess.run(['which', name], capture_output=True, text=True)
            if result.returncode == 0:
                return result.stdout.strip()

        # Check common locations
        common_paths = [
            '/usr/local/bin/trace_processor',
            '/usr/bin/trace_processor',
            os.path.expanduser('~/perfetto/out/linux/trace_processor'),
            os.path.expanduser('~/.local/bin/trace_processor'),
        ]
        for path in common_paths:
            if os.path.exists(path):
                return path

        raise FileNotFoundError(
            "trace_processor not found. Install from: "
            "https://perfetto.dev/docs/quickstart/trace-analysis"
        )

    def query(self, sql: str) -> list[dict]:
        """Execute SQL query and return results as list of dicts"""
        with tempfile.NamedTemporaryFile(mode='w', suffix='.sql', delete=False) as f:
            f.write(sql)
            query_file = f.name

        try:
            result = subprocess.run(
                [self.tp_path, self.trace_path, '-q', query_file],
                capture_output=True,
                text=True,
                timeout=120
            )

            if result.returncode != 0:
                # Some queries may fail if data doesn't exist, return empty
                return []

            # Parse CSV output
            lines = result.stdout.strip().split('\n')
            if len(lines) < 2:
                return []

            headers = lines[0].split(',')
            headers = [h.strip('"') for h in headers]

            rows = []
            for line in lines[1:]:
                if not line.strip():
                    continue
                # Handle CSV with potential quoted fields
                values = self._parse_csv_line(line)
                if len(values) == len(headers):
                    rows.append(dict(zip(headers, values)))

            return rows

        finally:
            os.unlink(query_file)

    def _parse_csv_line(self, line: str) -> list:
        """Parse a CSV line handling quoted fields"""
        values = []
        current = ""
        in_quotes = False

        for char in line:
            if char == '"':
                in_quotes = not in_quotes
            elif char == ',' and not in_quotes:
                values.append(current.strip().strip('"'))
                current = ""
            else:
                current += char

        values.append(current.strip().strip('"'))
        return values


class TraceAnalyzer:
    """Analyzes Perfetto traces and generates summaries"""

    def __init__(self, trace_path: str):
        self.tp = TraceProcessor(trace_path)
        self.summary = TraceSummary()

    def analyze(self) -> TraceSummary:
        """Run all analyses and return summary"""
        print("Analyzing trace...", file=sys.stderr)

        self._analyze_overview()
        self._analyze_scheduling_latency()
        self._analyze_per_cpu_stats()
        self._analyze_process_latency()
        self._analyze_thread_latency()
        self._analyze_sleep_stacks()
        self._analyze_uninterruptible_sleep()
        self._analyze_cpu_stacks()
        self._analyze_cpu_by_process()
        self._analyze_cpu_by_thread()
        self._analyze_counters()
        self._analyze_custom_events()
        self._detect_anomalies()

        return self.summary

    def _analyze_overview(self):
        """Get basic trace overview stats"""
        print("  - Overview...", file=sys.stderr)

        # Duration
        rows = self.tp.query("""
            SELECT
                (MAX(ts) - MIN(ts)) / 1e9 as duration_sec
            FROM sched_slice
        """)
        if rows:
            self.summary.duration_sec = float(rows[0].get('duration_sec', 0) or 0)

        # CPU count
        rows = self.tp.query("SELECT COUNT(DISTINCT cpu) as num_cpus FROM sched_slice")
        if rows:
            self.summary.num_cpus = int(rows[0].get('num_cpus', 0) or 0)

        # Process/thread count
        rows = self.tp.query("SELECT COUNT(DISTINCT upid) as cnt FROM process WHERE upid > 0")
        if rows:
            self.summary.num_processes = int(rows[0].get('cnt', 0) or 0)

        rows = self.tp.query("SELECT COUNT(DISTINCT utid) as cnt FROM thread WHERE utid > 0")
        if rows:
            self.summary.num_threads = int(rows[0].get('cnt', 0) or 0)

    def _analyze_scheduling_latency(self):
        """Analyze system-wide scheduling latency"""
        print("  - Scheduling latency...", file=sys.stderr)

        rows = self.tp.query("""
            SELECT
                COUNT(*) as count,
                MIN(dur) / 1000.0 as min_us,
                MAX(dur) / 1000.0 as max_us,
                AVG(dur) / 1000.0 as avg_us,
                SUM(dur) / 1000.0 as total_us
            FROM sched_slice
            WHERE dur > 0
        """)

        if rows and rows[0].get('count'):
            r = rows[0]
            self.summary.total_context_switches = int(r.get('count', 0) or 0)
            self.summary.system_latency.count = int(r.get('count', 0) or 0)
            self.summary.system_latency.min_us = float(r.get('min_us', 0) or 0)
            self.summary.system_latency.max_us = float(r.get('max_us', 0) or 0)
            self.summary.system_latency.avg_us = float(r.get('avg_us', 0) or 0)
            self.summary.system_latency.total_us = float(r.get('total_us', 0) or 0)

        # Percentiles (separate query for compatibility)
        rows = self.tp.query("""
            SELECT
                dur / 1000.0 as latency_us
            FROM sched_slice
            WHERE dur > 0
            ORDER BY dur
        """)

        if rows:
            latencies = [float(r['latency_us']) for r in rows if r.get('latency_us')]
            if latencies:
                n = len(latencies)
                self.summary.system_latency.p50_us = latencies[int(n * 0.50)]
                self.summary.system_latency.p95_us = latencies[int(n * 0.95)]
                self.summary.system_latency.p99_us = latencies[min(int(n * 0.99), n - 1)]

    def _analyze_per_cpu_stats(self):
        """Analyze per-CPU scheduling stats"""
        print("  - Per-CPU stats...", file=sys.stderr)

        rows = self.tp.query("""
            SELECT
                cpu,
                COUNT(*) as context_switches,
                AVG(dur) / 1000.0 as avg_latency_us,
                MAX(dur) / 1000.0 as max_latency_us,
                SUM(dur) / 1e9 as total_time_sec
            FROM sched_slice
            WHERE dur > 0
            GROUP BY cpu
            ORDER BY cpu
        """)

        self.summary.per_cpu_stats = [
            {
                'cpu': int(r.get('cpu', 0) or 0),
                'context_switches': int(r.get('context_switches', 0) or 0),
                'avg_latency_us': float(r.get('avg_latency_us', 0) or 0),
                'max_latency_us': float(r.get('max_latency_us', 0) or 0),
                'total_time_sec': float(r.get('total_time_sec', 0) or 0),
            }
            for r in rows
        ]

    def _analyze_process_latency(self):
        """Analyze scheduling latency by process"""
        print("  - Process latency...", file=sys.stderr)

        rows = self.tp.query("""
            SELECT
                p.name as process_name,
                p.pid,
                COUNT(*) as samples,
                AVG(s.dur) / 1000.0 as avg_us,
                MAX(s.dur) / 1000.0 as max_us,
                SUM(s.dur) / 1000.0 as total_us
            FROM sched_slice s
            JOIN thread t ON s.utid = t.utid
            JOIN process p ON t.upid = p.upid
            WHERE s.dur > 0 AND p.pid > 0
            GROUP BY p.pid
            ORDER BY max_us DESC
            LIMIT 20
        """)

        self.summary.top_processes_by_latency = [
            {
                'name': r.get('process_name', 'unknown'),
                'pid': int(r.get('pid', 0) or 0),
                'samples': int(r.get('samples', 0) or 0),
                'avg_us': float(r.get('avg_us', 0) or 0),
                'max_us': float(r.get('max_us', 0) or 0),
                'total_us': float(r.get('total_us', 0) or 0),
            }
            for r in rows
        ]

    def _analyze_thread_latency(self):
        """Analyze scheduling latency by thread"""
        print("  - Thread latency...", file=sys.stderr)

        rows = self.tp.query("""
            SELECT
                p.name as process_name,
                p.pid,
                t.name as thread_name,
                t.tid,
                COUNT(*) as samples,
                AVG(s.dur) / 1000.0 as avg_us,
                MAX(s.dur) / 1000.0 as max_us,
                SUM(s.dur) / 1000.0 as total_us
            FROM sched_slice s
            JOIN thread t ON s.utid = t.utid
            JOIN process p ON t.upid = p.upid
            WHERE s.dur > 0 AND p.pid > 0
            GROUP BY t.tid
            ORDER BY max_us DESC
            LIMIT 20
        """)

        self.summary.top_threads_by_latency = [
            {
                'process': r.get('process_name', 'unknown'),
                'pid': int(r.get('pid', 0) or 0),
                'thread': r.get('thread_name', 'unknown'),
                'tid': int(r.get('tid', 0) or 0),
                'samples': int(r.get('samples', 0) or 0),
                'avg_us': float(r.get('avg_us', 0) or 0),
                'max_us': float(r.get('max_us', 0) or 0),
                'total_us': float(r.get('total_us', 0) or 0),
            }
            for r in rows
        ]

    def _analyze_sleep_stacks(self):
        """Analyze sleep/blocking stack traces weighted by actual sleep duration"""
        print("  - Sleep stacks...", file=sys.stderr)

        # Join perf_sample with thread_state to get actual sleep durations
        # This weights stacks by how long they were actually blocked
        rows = self.tp.query("""
            WITH sleep_weighted AS (
                SELECT
                    ps.callsite_id,
                    ts.state,
                    SUM(ts.dur) / 1e6 as total_sleep_ms,
                    COUNT(*) as samples,
                    MAX(ts.dur) / 1e6 as max_sleep_ms
                FROM perf_sample ps
                JOIN thread_state ts ON ps.utid = ts.utid
                    AND ps.ts >= ts.ts
                    AND ps.ts < ts.ts + ts.dur
                WHERE ts.state IN ('S', 'D')
                GROUP BY ps.callsite_id, ts.state
            )
            SELECT
                callsite_id,
                state,
                total_sleep_ms,
                samples,
                max_sleep_ms
            FROM sleep_weighted
            WHERE total_sleep_ms > 1  -- Filter out noise
            ORDER BY total_sleep_ms DESC
            LIMIT 50
        """)

        if not rows:
            # Fallback to sample-based if no sleep correlation available
            self.summary.top_sleep_stacks = []
            return

        # Get full stacks for top sleep-weighted callsites
        total_sleep = sum(float(r.get('total_sleep_ms', 0) or 0) for r in rows)

        stack_data = []
        for r in rows[:20]:  # Process top 20
            callsite_id = int(r.get('callsite_id', 0))
            sleep_ms = float(r.get('total_sleep_ms', 0) or 0)
            state = r.get('state', 'S')
            samples = int(r.get('samples', 0) or 0)
            max_ms = float(r.get('max_sleep_ms', 0) or 0)

            full_stack = self._get_full_stack(callsite_id)

            stack_data.append({
                'stack': full_stack[:600],
                'sleep_ms': sleep_ms,
                'pct': round(100.0 * sleep_ms / max(total_sleep, 0.001), 2),
                'state': state,
                'samples': samples,
                'max_ms': max_ms,
            })

        self.summary.top_sleep_stacks = stack_data

    def _analyze_uninterruptible_sleep(self):
        """Find stack traces associated with uninterruptible sleep (D state)"""
        print("  - Uninterruptible sleep analysis...", file=sys.stderr)

        # Look for long scheduling events that might indicate D state
        # Perfetto doesn't directly expose task state, but we can infer from duration
        rows = self.tp.query("""
            SELECT
                p.name as process_name,
                p.pid,
                t.name as thread_name,
                t.tid,
                s.ts / 1e9 as time_sec,
                s.dur / 1000.0 as duration_us,
                s.end_state
            FROM sched_slice s
            JOIN thread t ON s.utid = t.utid
            JOIN process p ON t.upid = p.upid
            WHERE s.dur > 10000000  -- > 10ms (potential D state or contention)
            AND p.pid > 0
            ORDER BY s.dur DESC
            LIMIT 50
        """)

        self.summary.long_sleep_events = [
            {
                'process': r.get('process_name', 'unknown'),
                'pid': int(r.get('pid', 0) or 0),
                'thread': r.get('thread_name', 'unknown'),
                'tid': int(r.get('tid', 0) or 0),
                'time_sec': float(r.get('time_sec', 0) or 0),
                'duration_us': float(r.get('duration_us', 0) or 0),
                'state': r.get('end_state', 'unknown'),
            }
            for r in rows
        ]

        # Group by process to find patterns
        rows = self.tp.query("""
            SELECT
                p.name as process_name,
                p.pid,
                COUNT(*) as long_sleep_count,
                AVG(s.dur) / 1000.0 as avg_duration_us,
                MAX(s.dur) / 1000.0 as max_duration_us,
                SUM(s.dur) / 1000.0 as total_blocked_us
            FROM sched_slice s
            JOIN thread t ON s.utid = t.utid
            JOIN process p ON t.upid = p.upid
            WHERE s.dur > 10000000  -- > 10ms
            AND p.pid > 0
            GROUP BY p.pid
            ORDER BY total_blocked_us DESC
            LIMIT 20
        """)

        self.summary.uninterruptible_sleep_stacks = [
            {
                'process': r.get('process_name', 'unknown'),
                'pid': int(r.get('pid', 0) or 0),
                'long_sleep_count': int(r.get('long_sleep_count', 0) or 0),
                'avg_duration_us': float(r.get('avg_duration_us', 0) or 0),
                'max_duration_us': float(r.get('max_duration_us', 0) or 0),
                'total_blocked_us': float(r.get('total_blocked_us', 0) or 0),
            }
            for r in rows
        ]

    def _analyze_cpu_stacks(self):
        """Analyze CPU-bound stack traces (hotspots)"""
        print("  - CPU stacks (hotspots)...", file=sys.stderr)

        # Get all functions from stack profile (systing stores stacks here)
        # Count how often each function appears in any stack
        rows = self.tp.query("""
            SELECT
                f.name as function_name,
                m.name as module,
                COUNT(*) as sample_count
            FROM stack_profile_callsite c
            JOIN stack_profile_frame f ON c.frame_id = f.id
            LEFT JOIN stack_profile_mapping m ON f.mapping = m.id
            WHERE f.name IS NOT NULL AND f.name != ''
            GROUP BY f.name
            ORDER BY sample_count DESC
            LIMIT 40
        """)

        total_samples = sum(int(r.get('sample_count', 0) or 0) for r in rows)

        self.summary.top_cpu_stacks = [
            {
                'function': self._clean_function_name(r.get('function_name', 'unknown')),
                'module': self._clean_module_name(r.get('module')),
                'samples': int(r.get('sample_count', 0) or 0),
                'pct': round(100.0 * int(r.get('sample_count', 0) or 0) / max(total_samples, 1), 2),
            }
            for r in rows
        ]

    def _clean_function_name(self, name: str) -> str:
        """Extract clean function name from systing's format"""
        if not name:
            return 'unknown'
        # Systing format: "func_name (module) <address>"
        # Extract just the function name
        if ' (' in name:
            return name.split(' (')[0]
        if ' <' in name:
            return name.split(' <')[0]
        return name[:60]

    def _clean_module_name(self, name: Optional[str]) -> str:
        """Extract clean module name"""
        if not name:
            return 'kernel'
        # Get just the filename
        return name.split('/')[-1] if '/' in name else name

    def _get_full_stack(self, callsite_id: int) -> str:
        """Reconstruct full stack trace from callsite_id"""
        rows = self.tp.query(f"""
            WITH RECURSIVE stack_walk AS (
                SELECT id, parent_id, frame_id, 0 as depth
                FROM stack_profile_callsite
                WHERE id = {callsite_id}
                UNION ALL
                SELECT c.id, c.parent_id, c.frame_id, sw.depth + 1
                FROM stack_profile_callsite c
                JOIN stack_walk sw ON c.id = sw.parent_id
            )
            SELECT f.name as function_name
            FROM stack_walk sw
            JOIN stack_profile_frame f ON sw.frame_id = f.id
            ORDER BY sw.depth DESC
        """)

        if not rows:
            return "unknown"

        # Build stack string, cleaning up function names
        funcs = []
        for r in rows:
            name = r.get('function_name', 'unknown')
            clean_name = self._clean_function_name(name)
            funcs.append(clean_name)

        return ' -> '.join(funcs[-10:])  # Last 10 frames

    def _analyze_cpu_by_process(self):
        """Analyze CPU usage by process"""
        print("  - CPU by process...", file=sys.stderr)

        rows = self.tp.query("""
            SELECT
                p.name as process_name,
                p.pid,
                COUNT(*) as sample_count,
                SUM(s.dur) / 1e9 as cpu_time_sec
            FROM sched_slice s
            JOIN thread t ON s.utid = t.utid
            JOIN process p ON t.upid = p.upid
            WHERE s.dur > 0 AND p.pid > 0
            GROUP BY p.pid
            ORDER BY cpu_time_sec DESC
            LIMIT 20
        """)

        total_cpu = sum(float(r.get('cpu_time_sec', 0) or 0) for r in rows)

        self.summary.cpu_hotspots_by_process = [
            {
                'process': r.get('process_name', 'unknown'),
                'pid': int(r.get('pid', 0) or 0),
                'samples': int(r.get('sample_count', 0) or 0),
                'cpu_time_sec': float(r.get('cpu_time_sec', 0) or 0),
                'pct': round(100.0 * float(r.get('cpu_time_sec', 0) or 0) / max(total_cpu, 0.001), 2),
            }
            for r in rows
        ]

    def _analyze_cpu_by_thread(self):
        """Analyze CPU usage by thread"""
        print("  - CPU by thread...", file=sys.stderr)

        rows = self.tp.query("""
            SELECT
                p.name as process_name,
                p.pid,
                t.name as thread_name,
                t.tid,
                COUNT(*) as sample_count,
                SUM(s.dur) / 1e9 as cpu_time_sec
            FROM sched_slice s
            JOIN thread t ON s.utid = t.utid
            JOIN process p ON t.upid = p.upid
            WHERE s.dur > 0 AND p.pid > 0
            GROUP BY t.tid
            ORDER BY cpu_time_sec DESC
            LIMIT 30
        """)

        total_cpu = sum(float(r.get('cpu_time_sec', 0) or 0) for r in rows)

        self.summary.cpu_hotspots_by_thread = [
            {
                'process': r.get('process_name', 'unknown'),
                'pid': int(r.get('pid', 0) or 0),
                'thread': r.get('thread_name', 'unknown'),
                'tid': int(r.get('tid', 0) or 0),
                'samples': int(r.get('sample_count', 0) or 0),
                'cpu_time_sec': float(r.get('cpu_time_sec', 0) or 0),
                'pct': round(100.0 * float(r.get('cpu_time_sec', 0) or 0) / max(total_cpu, 0.001), 2),
            }
            for r in rows
        ]

    def _analyze_counters(self):
        """Analyze counter tracks (perf counters, runqueue, etc.)"""
        print("  - Counters...", file=sys.stderr)

        # Runqueue stats
        rows = self.tp.query("""
            SELECT
                track.name as counter_name,
                AVG(counter.value) as avg_value,
                MAX(counter.value) as max_value,
                MIN(counter.value) as min_value,
                COUNT(*) as sample_count
            FROM counter
            JOIN counter_track track ON counter.track_id = track.id
            WHERE track.name LIKE '%runqueue%' OR track.name LIKE '%rq%'
            GROUP BY track.name
        """)

        self.summary.runqueue_stats = [
            {
                'name': r.get('counter_name', 'unknown'),
                'avg': float(r.get('avg_value', 0) or 0),
                'max': float(r.get('max_value', 0) or 0),
                'min': float(r.get('min_value', 0) or 0),
                'samples': int(r.get('sample_count', 0) or 0),
            }
            for r in rows
        ]

        # Perf counters
        rows = self.tp.query("""
            SELECT
                track.name as counter_name,
                AVG(counter.value) as avg_value,
                MAX(counter.value) as max_value,
                SUM(counter.value) as total_value,
                COUNT(*) as sample_count
            FROM counter
            JOIN counter_track track ON counter.track_id = track.id
            WHERE track.name NOT LIKE '%runqueue%'
            AND track.name NOT LIKE '%rq%'
            AND track.name NOT LIKE '%latency%'
            GROUP BY track.name
            ORDER BY total_value DESC
            LIMIT 20
        """)

        self.summary.perf_counters = [
            {
                'name': r.get('counter_name', 'unknown'),
                'avg': float(r.get('avg_value', 0) or 0),
                'max': float(r.get('max_value', 0) or 0),
                'total': float(r.get('total_value', 0) or 0),
                'samples': int(r.get('sample_count', 0) or 0),
            }
            for r in rows
        ]

    def _analyze_custom_events(self):
        """Analyze custom slice events (from --trace-event)"""
        print("  - Custom events...", file=sys.stderr)

        rows = self.tp.query("""
            SELECT
                name,
                COUNT(*) as count,
                AVG(dur) / 1000.0 as avg_us,
                MAX(dur) / 1000.0 as max_us,
                MIN(dur) / 1000.0 as min_us,
                SUM(dur) / 1000.0 as total_us
            FROM slice
            WHERE dur > 0
            GROUP BY name
            ORDER BY count DESC
            LIMIT 30
        """)

        self.summary.custom_events = [
            {
                'name': r.get('name', 'unknown'),
                'count': int(r.get('count', 0) or 0),
                'avg_us': float(r.get('avg_us', 0) or 0),
                'max_us': float(r.get('max_us', 0) or 0),
                'min_us': float(r.get('min_us', 0) or 0),
                'total_us': float(r.get('total_us', 0) or 0),
            }
            for r in rows
        ]

    def _detect_anomalies(self):
        """Detect potential issues in the trace"""
        print("  - Anomaly detection...", file=sys.stderr)

        anomalies = []

        # Check for very long scheduling delays (> 100ms)
        if self.summary.system_latency.max_us > 100000:
            anomalies.append({
                'severity': 'warning',
                'type': 'long_scheduling_delay',
                'message': f"Maximum scheduling delay of {self.summary.system_latency.max_us / 1000:.1f}ms detected",
            })

        # Check for high p99 latency (> 50ms)
        if self.summary.system_latency.p99_us > 50000:
            anomalies.append({
                'severity': 'warning',
                'type': 'high_p99_latency',
                'message': f"P99 scheduling latency is {self.summary.system_latency.p99_us / 1000:.1f}ms",
            })

        # Check for processes with excessive blocking
        for proc in self.summary.uninterruptible_sleep_stacks[:5]:
            if proc.get('total_blocked_us', 0) > 1000000:  # > 1 second total
                anomalies.append({
                    'severity': 'info',
                    'type': 'excessive_blocking',
                    'message': f"Process '{proc['process']}' (PID {proc['pid']}) spent {proc['total_blocked_us'] / 1e6:.2f}s blocked",
                })

        # Check for CPU imbalance
        if self.summary.per_cpu_stats:
            cpu_times = [c.get('total_time_sec', 0) for c in self.summary.per_cpu_stats]
            if cpu_times:
                avg_time = sum(cpu_times) / len(cpu_times)
                max_time = max(cpu_times)
                if avg_time > 0 and max_time > avg_time * 1.5:
                    anomalies.append({
                        'severity': 'info',
                        'type': 'cpu_imbalance',
                        'message': f"CPU load imbalance detected: max CPU has {max_time / avg_time:.1f}x average load",
                    })

        self.summary.anomalies = anomalies


def format_markdown(summary: TraceSummary) -> str:
    """Format summary as Markdown"""
    lines = []

    lines.append("# Systing Trace Analysis Summary\n")

    # Overview
    lines.append("## Overview\n")
    lines.append(f"- **Duration**: {summary.duration_sec:.2f} seconds")
    lines.append(f"- **CPUs**: {summary.num_cpus}")
    lines.append(f"- **Processes**: {summary.num_processes}")
    lines.append(f"- **Threads**: {summary.num_threads}")
    lines.append(f"- **Total Context Switches**: {summary.total_context_switches:,}")
    lines.append("")

    # Anomalies (if any)
    if summary.anomalies:
        lines.append("## Anomalies Detected\n")
        for a in summary.anomalies:
            icon = "⚠️" if a['severity'] == 'warning' else "ℹ️"
            lines.append(f"- {icon} **{a['type']}**: {a['message']}")
        lines.append("")

    # System-wide scheduling latency
    lines.append("## Scheduling Latency (System-wide)\n")
    lat = summary.system_latency
    lines.append("| Metric | Value |")
    lines.append("|--------|-------|")
    lines.append(f"| Samples | {lat.count:,} |")
    lines.append(f"| Min | {lat.min_us:.1f} µs |")
    lines.append(f"| Avg | {lat.avg_us:.1f} µs |")
    lines.append(f"| P50 | {lat.p50_us:.1f} µs |")
    lines.append(f"| P95 | {lat.p95_us:.1f} µs |")
    lines.append(f"| P99 | {lat.p99_us:.1f} µs |")
    lines.append(f"| Max | {lat.max_us:.1f} µs |")
    lines.append("")

    # Per-CPU stats
    if summary.per_cpu_stats:
        lines.append("## Per-CPU Statistics\n")
        lines.append("| CPU | Context Switches | Avg Latency (µs) | Max Latency (µs) | Total Time (s) |")
        lines.append("|-----|------------------|------------------|------------------|----------------|")
        for cpu in summary.per_cpu_stats:
            lines.append(f"| {cpu['cpu']} | {cpu['context_switches']:,} | {cpu['avg_latency_us']:.1f} | {cpu['max_latency_us']:.1f} | {cpu['total_time_sec']:.2f} |")
        lines.append("")

    # Top processes by latency
    if summary.top_processes_by_latency:
        lines.append("## Top Processes by Scheduling Latency\n")
        lines.append("| Process | PID | Samples | Avg (µs) | Max (µs) | Total (ms) |")
        lines.append("|---------|-----|---------|----------|----------|------------|")
        for p in summary.top_processes_by_latency[:15]:
            lines.append(f"| {p['name'][:20]} | {p['pid']} | {p['samples']:,} | {p['avg_us']:.1f} | {p['max_us']:.1f} | {p['total_us'] / 1000:.1f} |")
        lines.append("")

    # Top threads by latency
    if summary.top_threads_by_latency:
        lines.append("## Top Threads by Scheduling Latency\n")
        lines.append("| Process | Thread | TID | Max (µs) | Total (ms) |")
        lines.append("|---------|--------|-----|----------|------------|")
        for t in summary.top_threads_by_latency[:15]:
            lines.append(f"| {t['process'][:15]} | {t['thread'][:15]} | {t['tid']} | {t['max_us']:.1f} | {t['total_us'] / 1000:.1f} |")
        lines.append("")

    # Long sleep events
    if summary.long_sleep_events:
        lines.append("## Long Blocking Events (>10ms)\n")
        lines.append("| Time (s) | Process | Thread | Duration (ms) | State |")
        lines.append("|----------|---------|--------|---------------|-------|")
        for e in summary.long_sleep_events[:20]:
            lines.append(f"| {e['time_sec']:.3f} | {e['process'][:15]} | {e['thread'][:15]} | {e['duration_us'] / 1000:.1f} | {e['state']} |")
        lines.append("")

    # Processes with excessive blocking
    if summary.uninterruptible_sleep_stacks:
        lines.append("## Processes with High Blocking Time\n")
        lines.append("| Process | PID | Events | Avg (ms) | Max (ms) | Total (ms) |")
        lines.append("|---------|-----|--------|----------|----------|------------|")
        for p in summary.uninterruptible_sleep_stacks[:15]:
            lines.append(f"| {p['process'][:20]} | {p['pid']} | {p['long_sleep_count']} | {p['avg_duration_us'] / 1000:.1f} | {p['max_duration_us'] / 1000:.1f} | {p['total_blocked_us'] / 1000:.1f} |")
        lines.append("")

    # CPU hotspots by function
    if summary.top_cpu_stacks:
        lines.append("## CPU Hotspots (Top Functions)\n")
        lines.append("| Function | Module | Samples | % |")
        lines.append("|----------|--------|---------|---|")
        for f in summary.top_cpu_stacks[:20]:
            func_name = f['function'][:40] if f['function'] else 'unknown'
            module = (f['module'] or 'unknown').split('/')[-1][:20]
            lines.append(f"| {func_name} | {module} | {f['samples']:,} | {f['pct']:.1f}% |")
        lines.append("")

    # CPU by process
    if summary.cpu_hotspots_by_process:
        lines.append("## CPU Time by Process\n")
        lines.append("| Process | PID | CPU Time (s) | % |")
        lines.append("|---------|-----|--------------|---|")
        for p in summary.cpu_hotspots_by_process[:15]:
            lines.append(f"| {p['process'][:25]} | {p['pid']} | {p['cpu_time_sec']:.2f} | {p['pct']:.1f}% |")
        lines.append("")

    # CPU by thread
    if summary.cpu_hotspots_by_thread:
        lines.append("## CPU Time by Thread\n")
        lines.append("| Process | Thread | TID | CPU Time (s) | % |")
        lines.append("|---------|--------|-----|--------------|---|")
        for t in summary.cpu_hotspots_by_thread[:20]:
            lines.append(f"| {t['process'][:15]} | {t['thread'][:15]} | {t['tid']} | {t['cpu_time_sec']:.2f} | {t['pct']:.1f}% |")
        lines.append("")

    # Stack traces weighted by sleep time
    if summary.top_sleep_stacks:
        lines.append("## Top Sleep Stacks (by total sleep time)\n")
        lines.append("Stacks weighted by actual time spent blocked, not sample count.\n")
        lines.append("Stack format: caller -> ... -> leaf function\n")
        for i, s in enumerate(summary.top_sleep_stacks[:10], 1):
            sleep_ms = s.get('sleep_ms', 0)
            max_ms = s.get('max_ms', 0)
            state = s.get('state', 'S')
            samples = s.get('samples', 0)
            state_label = 'D (uninterruptible)' if state == 'D' else 'S (interruptible)'

            lines.append(f"**{i}. Total: {sleep_ms:.1f}ms ({s['pct']:.1f}%) | Max: {max_ms:.1f}ms | State: {state_label} | Samples: {samples}**")

            # Split stack by ' -> ' and format as indented list
            stack_parts = s['stack'].split(' -> ')
            if len(stack_parts) > 1:
                lines.append("```")
                for j, func in enumerate(stack_parts):
                    indent = "  " * j
                    lines.append(f"{indent}{func}")
                lines.append("```")
            else:
                lines.append(f"  `{s['stack'][:200]}`")
            lines.append("")

    # Counters
    if summary.runqueue_stats:
        lines.append("## Runqueue Statistics\n")
        lines.append("| Counter | Avg | Max |")
        lines.append("|---------|-----|-----|")
        for c in summary.runqueue_stats:
            lines.append(f"| {c['name']} | {c['avg']:.2f} | {c['max']:.0f} |")
        lines.append("")

    if summary.perf_counters:
        lines.append("## Performance Counters\n")
        lines.append("| Counter | Avg | Max | Total |")
        lines.append("|---------|-----|-----|-------|")
        for c in summary.perf_counters[:15]:
            lines.append(f"| {c['name'][:30]} | {c['avg']:.2f} | {c['max']:.0f} | {c['total']:.0f} |")
        lines.append("")

    # Custom events
    if summary.custom_events:
        lines.append("## Custom Events\n")
        lines.append("| Event | Count | Avg (µs) | Max (µs) | Total (ms) |")
        lines.append("|-------|-------|----------|----------|------------|")
        for e in summary.custom_events[:20]:
            lines.append(f"| {e['name'][:30]} | {e['count']:,} | {e['avg_us']:.1f} | {e['max_us']:.1f} | {e['total_us'] / 1000:.1f} |")
        lines.append("")

    return "\n".join(lines)


def format_json(summary: TraceSummary) -> str:
    """Format summary as JSON"""
    return json.dumps(asdict(summary), indent=2)


def main():
    parser = argparse.ArgumentParser(
        description='Analyze systing Perfetto traces and generate summaries',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
    %(prog)s trace.pb                        # Print markdown summary to stdout
    %(prog)s trace.pb --format json          # Print JSON summary
    %(prog)s trace.pb -o summary.md          # Save to file
    %(prog)s trace.pb --format json -o summary.json
        """
    )
    parser.add_argument('trace', help='Path to Perfetto trace file (.pb)')
    parser.add_argument('--format', '-f', choices=['markdown', 'json'], default='markdown',
                        help='Output format (default: markdown)')
    parser.add_argument('--output', '-o', help='Output file (default: stdout)')

    args = parser.parse_args()

    if not os.path.exists(args.trace):
        print(f"Error: Trace file not found: {args.trace}", file=sys.stderr)
        sys.exit(1)

    try:
        analyzer = TraceAnalyzer(args.trace)
        summary = analyzer.analyze()

        if args.format == 'json':
            output = format_json(summary)
        else:
            output = format_markdown(summary)

        if args.output:
            with open(args.output, 'w') as f:
                f.write(output)
            print(f"Summary written to {args.output}", file=sys.stderr)
        else:
            print(output)

    except FileNotFoundError as e:
        print(f"Error: {e}", file=sys.stderr)
        sys.exit(1)
    except Exception as e:
        print(f"Error analyzing trace: {e}", file=sys.stderr)
        sys.exit(1)


if __name__ == '__main__':
    main()
